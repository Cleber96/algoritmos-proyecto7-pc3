{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaf46a59",
   "metadata": {},
   "source": [
    "# benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8e5427",
   "metadata": {},
   "source": [
    "un Índice de Modelo Recursivo (RMI) y un B-Tree Ambos están diseñados para una cosa principal: encontrar datos rápidamente en un conjunto grande y ordenado. Pero, ¿cuál es mejor y bajo qué circunstancias?\n",
    "\n",
    "Aquí es donde entra el benchmarking. Imagina que tienes dos autos deportivos y quieres saber cuál es más rápido, cuánto combustible gasta o cuánto espacio tiene para equipaje. El benchmarking es eso, pero para algoritmos y estructuras de datos. Nos permite medir y comparar su rendimiento de manera justa y objetiva.\n",
    "\n",
    "En este cuaderno, aprenderemos a:\n",
    "\n",
    "    Entender qué es el benchmarking y por qué es vital.\n",
    "    Configurar un entorno para medir tiempos de construcción y búsqueda.\n",
    "    Ejecutar pruebas con diferentes tamaños de datos.\n",
    "    Recopilar los resultados para un análisis posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fd8c12",
   "metadata": {},
   "source": [
    "### Preparación: Importando Nuestras Herramientas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f8e96",
   "metadata": {},
   "source": [
    "Para ejecutar nuestro benchmark, necesitamos importar las clases y funciones que hemos construido en cuadernos anteriores:\n",
    "\n",
    "    Nuestra implementación del RMI (rmi_model).\n",
    "    Nuestra implementación del B-Tree (btree).\n",
    "    Nuestras utilidades (utils) para generar datos y medir tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008211b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys # Para medir el uso de memoria (aproximado)\n",
    "\n",
    "# Importamos nuestras implementaciones\n",
    "# Asegúrate de que tu ruta de Python esté configurada para encontrar el directorio 'src'\n",
    "# Si estás ejecutando esto directamente en el directorio 'notebook', puede que necesites añadir esto:\n",
    "import os\n",
    "import sys\n",
    "if os.getcwd().endswith('notebook'):\n",
    "    sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../src')))\n",
    "\n",
    "from rmi.rmi_model import RMI, train_linear_model, predict_linear_model # Importa la clase RMI y las funciones auxiliares\n",
    "from btree.btree import BTree, BTreeNode # Importa la clase BTree y BTreeNode\n",
    "from rmi.utils import generate_sorted_data, measure_time # Importa nuestras utilidades\n",
    "\n",
    "print(\"Librerías y módulos importados correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64f6ebb",
   "metadata": {},
   "source": [
    "Métricas Clave del Benchmarking\n",
    "\n",
    "Para comparar el RMI y el B-Tree, nos centraremos en tres métricas principales:\n",
    "\n",
    "    Tiempo de Construcción del Índice: ¿Cuánto tiempo tarda cada estructura en organizarse para poder buscar datos? Para el RMI, es el tiempo de entrenamiento de sus modelos. Para el B-Tree, es el tiempo de insertar todos los elementos.\n",
    "    Tiempo de Búsqueda de un Elemento: Una vez que el índice está construido, ¿cuánto tarda en encontrar un valor específico? Mediremos el tiempo promedio de muchas búsquedas para obtener una métrica representativa.\n",
    "    Espacio Ocupado (Memoria): ¿Cuánta memoria RAM consume cada índice para almacenar su estructura? Esto es crucial para sistemas con recursos limitados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cba556",
   "metadata": {},
   "source": [
    "Configuración de los Parámetros del Benchmark\n",
    "\n",
    "Definiremos los tamaños de los datasets con los que queremos probar, el número de búsquedas a realizar para promediar los tiempos, y los parámetros específicos de cada estructura (como el orden del B-Tree o el número de modelos del Nivel 1 del RMI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d705f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parámetros del Benchmark ---\n",
    "\n",
    "# Diferentes tamaños de datasets para probar\n",
    "# Esto nos permitirá ver cómo escalan las estructuras con más datos.\n",
    "dataset_sizes = [10_000, 100_000, 500_000, 1_000_000, 5_000_000, 10_000_000] # ¡Cuidado con el tiempo en los más grandes!\n",
    "\n",
    "# Número de búsquedas a realizar para cada dataset, para obtener un promedio confiable\n",
    "num_searches = 10_000\n",
    "\n",
    "# Parámetros del B-Tree\n",
    "B_TREE_ORDER = 100 # Un orden alto para simular nodos grandes, como bloques de disco\n",
    "\n",
    "# Parámetros del RMI\n",
    "# Este valor es crucial para el RMI. Más modelos = más precisión (y más memoria)\n",
    "RMI_LEVEL1_MODELS = 1000 \n",
    "# Buffer de la búsqueda local en RMI (qué tan amplio busca alrededor de la predicción)\n",
    "RMI_SEARCH_WINDOW_BUFFER = 100 \n",
    "\n",
    "print(f\"Parámetros del B-Tree: Orden = {B_TREE_ORDER}\")\n",
    "print(f\"Parámetros del RMI: Modelos Nivel 1 = {RMI_LEVEL1_MODELS}, Ventana de búsqueda = {RMI_SEARCH_WINDOW_BUFFER}\")\n",
    "print(f\"Número de búsquedas por test: {num_searches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eb1b43",
   "metadata": {},
   "source": [
    "Estructura para Almacenar los Resultados\n",
    "\n",
    "Vamos a almacenar los resultados en un diccionario o una lista de diccionarios para poder analizar y visualizar fácilmente más tarde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c4115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Almacenamiento de Resultados ---\n",
    "results = [] # Lista para guardar los resultados de cada tamaño de dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd332c",
   "metadata": {},
   "source": [
    "Ejecutando el Benchmark Paso a Paso\n",
    "\n",
    "Ahora, crearemos un bucle que iterará sobre cada tamaño de dataset, realizará las operaciones y medirá el tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d7c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Iniciando el Proceso de Benchmarking ---\")\n",
    "\n",
    "for size in dataset_sizes:\n",
    "    print(f\"\\n--- Probando con un dataset de tamaño: {size:,} ---\")\n",
    "    \n",
    "    # 1. Generar Datos\n",
    "    # Usamos nuestra utilidad para asegurar que los datos estén ordenados\n",
    "    data, gen_time = measure_time(generate_sorted_data, size)\n",
    "    print(f\"Datos generados en {gen_time:.4f} segundos.\")\n",
    "\n",
    "    # 2. Preparar valores de búsqueda aleatorios (que existan en el dataset)\n",
    "    # Esto asegura que estamos buscando valores que realmente se pueden encontrar.\n",
    "    search_keys_indices = np.random.randint(0, size, num_searches)\n",
    "    search_keys = data[search_keys_indices]\n",
    "    \n",
    "    # --- Benchmarking del RMI ---\n",
    "    print(\"\\n  >> RMI:\")\n",
    "    \n",
    "    # Construcción del RMI\n",
    "    # Recordamos los parámetros que le pasamos al constructor de RMI\n",
    "    rmi_instance, rmi_build_time = measure_time(RMI, data, RMI_LEVEL1_MODELS, RMI_SEARCH_WINDOW_BUFFER)\n",
    "    print(f\"    Tiempo de construcción del RMI: {rmi_build_time:.6f} segundos.\")\n",
    "\n",
    "    # Búsqueda en el RMI\n",
    "    total_rmi_search_time = 0\n",
    "    for key in search_keys:\n",
    "        _, search_time = measure_time(rmi_instance.search, key)\n",
    "        total_rmi_search_time += search_time\n",
    "    avg_rmi_search_time = total_rmi_search_time / num_searches\n",
    "    print(f\"    Tiempo promedio de búsqueda del RMI ({num_searches} búsquedas): {avg_rmi_search_time:.9f} segundos.\")\n",
    "\n",
    "    # Medida de memoria del RMI (aproximada)\n",
    "    # Esto es complejo y sys.getsizeof no es preciso para estructuras anidadas.\n",
    "    # Para una medida más precisa se necesitaría algo como `pympler.asizeof` o análisis profundo.\n",
    "    # Aquí, una estimación muy básica del objeto principal, no de todos los componentes internos.\n",
    "    rmi_memory = sys.getsizeof(rmi_instance) + sys.getsizeof(rmi_instance.level0_model) + \\\n",
    "                 sum(sys.getsizeof(m) for m in rmi_instance.level1_models if m is not None)\n",
    "    print(f\"    Uso de memoria del RMI (aprox.): {rmi_memory / (1024*1024):.4f} MB.\")\n",
    "\n",
    "\n",
    "    # --- Benchmarking del B-Tree ---\n",
    "    print(\"\\n  >> B-Tree:\")\n",
    "\n",
    "    # Construcción del B-Tree\n",
    "    # Reiniciamos el B-Tree para cada prueba de tamaño de datos\n",
    "    b_tree_instance = BTree(B_TREE_ORDER)\n",
    "    \n",
    "    # Insertar todas las claves en el B-Tree\n",
    "    b_tree_build_start = time.perf_counter()\n",
    "    for key in data: # Insertamos todos los datos originales\n",
    "        b_tree_instance.insert(key)\n",
    "    b_tree_build_time = time.perf_counter() - b_tree_build_start\n",
    "    print(f\"    Tiempo de construcción del B-Tree: {b_tree_build_time:.6f} segundos.\")\n",
    "\n",
    "    # Búsqueda en el B-Tree\n",
    "    total_btree_search_time = 0\n",
    "    for key in search_keys:\n",
    "        _, search_time = measure_time(b_tree_instance.search, key)\n",
    "        total_btree_search_time += search_time\n",
    "    avg_btree_search_time = total_btree_search_time / num_searches\n",
    "    print(f\"    Tiempo promedio de búsqueda del B-Tree ({num_searches} búsquedas): {avg_btree_search_time:.9f} segundos.\")\n",
    "\n",
    "    # Medida de memoria del B-Tree (aproximada y más compleja de calcular con precisión)\n",
    "    # Calcular la memoria exacta de un B-Tree Python con muchos nodos es difícil sin herramientas de profiling.\n",
    "    # sys.getsizeof solo da el tamaño del objeto \"BTree\" o \"BTreeNode\", no de todo el árbol recursivamente.\n",
    "    # Para una estimación básica de un nodo, podemos ver:\n",
    "    # b_tree_memory_per_node = sys.getsizeof(BTreeNode(B_TREE_ORDER, True)) # Tamaño de un nodo vacío\n",
    "    # b_tree_approx_nodes = size / (B_TREE_ORDER -1) # Estimación del número de nodos (muy burda)\n",
    "    # b_tree_total_memory_approx = b_tree_approx_nodes * b_tree_memory_per_node # Muy impreciso\n",
    "    # Para esta demo, lo dejaremos como un placeholder.\n",
    "    # Una medida más precisa requeriría `pympler.asizeof` o un análisis recursivo.\n",
    "    \n",
    "    # Placeholder para memoria del B-Tree - Nota: La memoria real de un B-Tree es muy compleja de calcular\n",
    "    # con sys.getsizeof debido a la estructura de nodos y enlaces. Esto es solo una aproximación.\n",
    "    # En un escenario real, usaríamos herramientas de profiling de memoria.\n",
    "    btree_memory = sys.getsizeof(b_tree_instance) # Tamaño del objeto BTree\n",
    "    # Puedes añadir aquí una lógica para recorrer nodos y sumar sus tamaños, pero es complejo.\n",
    "    print(f\"    Uso de memoria del B-Tree (objeto principal, aprox.): {btree_memory / (1024*1024):.4f} MB.\")\n",
    "\n",
    "\n",
    "    # --- Guardar Resultados ---\n",
    "    results.append({\n",
    "        'dataset_size': size,\n",
    "        'rmi_build_time': rmi_build_time,\n",
    "        'rmi_avg_search_time': avg_rmi_search_time,\n",
    "        'rmi_memory_mb': rmi_memory / (1024*1024),\n",
    "        'btree_build_time': b_tree_build_time,\n",
    "        'btree_avg_search_time': avg_btree_search_time,\n",
    "        'btree_memory_mb': btree_memory / (1024*1024) # Placeholder\n",
    "    })\n",
    "\n",
    "print(\"\\n--- Benchmarking Completado ---\")\n",
    "\n",
    "# Mostrar un resumen de los resultados\n",
    "print(\"\\n--- Resumen de Resultados ---\")\n",
    "for r in results:\n",
    "    print(f\"\\nTamaño: {r['dataset_size']:,}\")\n",
    "    print(f\"  RMI  - Construcción: {r['rmi_build_time']:.6f} s, Búsqueda: {r['rmi_avg_search_time']:.9f} s, Memoria (aprox): {r['rmi_memory_mb']:.4f} MB\")\n",
    "    print(f\"  B-Tree - Construcción: {r['btree_build_time']:.6f} s, Búsqueda: {r['btree_avg_search_time']:.9f} s, Memoria (aprox): {r['btree_memory_mb']:.4f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67017535",
   "metadata": {},
   "source": [
    "Análisis Preliminar de los Resultados\n",
    "\n",
    "Al observar los resultados impresos, incluso antes de graficarlos, podemos empezar a ver patrones:\n",
    "\n",
    "    Tiempo de Construcción: Generalmente, construir un B-Tree implica insertar cada elemento uno por uno, lo que puede ser más lento para grandes datasets. El RMI, por otro lado, entrena modelos en una pasada, lo que a menudo es más rápido.\n",
    "    Tiempo de Búsqueda: Aquí es donde el RMI busca destacar. Su objetivo es acercarse a la velocidad de una búsqueda binaria (o incluso superarla) en promedio, mientras que el B-Tree tiene una complejidad logarítmica garantizada, pero con más \"saltos\" entre nodos.\n",
    "    Uso de Memoria: Este es un punto clave. El RMI almacena solo los parámetros de sus modelos (unos pocos números por modelo), lo que tiende a ser muy compacto. El B-Tree almacena cada clave y puntero en sus nodos, lo que puede consumir significativamente más memoria para datasets muy grandes.\n",
    "\n",
    "Los números exactos variarán en cada ejecución y máquina, pero las tendencias generales deberían ser evidentes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
