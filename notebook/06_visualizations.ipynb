{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ff32e3",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1921e86",
   "metadata": {},
   "source": [
    "Preparación: Importando Matplotlib y Nuestros Datos\n",
    "\n",
    "Necesitaremos la popular librería Matplotlib para crear nuestras gráficas. Además, necesitaremos los resultados que generamos en el cuaderno 05_benchmarking.ipynb. Para simplificar, asumiremos que los resultados ya están cargados o los re-ejecutaremos si es necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d8233",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Para asegurar que los resultados del benchmark estén disponibles,\n",
    "# podemos re-ejecutar el benchmark aquí o simularlos.\n",
    "# Para una exposición en vivo, lo ideal sería haber guardado los resultados del 05_benchmarking.ipynb\n",
    "# y cargarlos aquí. Por simplicidad en este cuaderno, definiremos una estructura de resultados de ejemplo.\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# ATENCIÓN: En una ejecución real, el cuaderno 05_benchmarking.ipynb debería guardar sus resultados\n",
    "# (por ejemplo, en un archivo JSON o pickle) y este cuaderno los cargaría.\n",
    "# Para fines de esta explicación, voy a crear un conjunto de resultados simulados\n",
    "# que reflejan patrones típicos esperados.\n",
    "# En un proyecto real, reemplazarías esto con la carga de tus datos reales.\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Datos simulados que replicarían lo que obtendríamos del benchmark real\n",
    "# Estos datos son para propósitos de demostración si no ejecutas 05_benchmarking.ipynb antes.\n",
    "# Si ejecutas el 05_benchmarking.ipynb, puedes copiar y pegar la variable 'results' desde allí.\n",
    "\n",
    "results = [\n",
    "    {'dataset_size': 10_000, 'rmi_build_time': 0.005, 'rmi_avg_search_time': 0.000001, 'rmi_memory_mb': 0.0001,\n",
    "     'btree_build_time': 0.01, 'btree_avg_search_time': 0.000002, 'btree_memory_mb': 0.0005},\n",
    "    {'dataset_size': 100_000, 'rmi_build_time': 0.04, 'rmi_avg_search_time': 0.0000012, 'rmi_memory_mb': 0.0002,\n",
    "     'btree_build_time': 0.15, 'btree_avg_search_time': 0.0000025, 'btree_memory_mb': 0.005},\n",
    "    {'dataset_size': 500_000, 'rmi_build_time': 0.2, 'rmi_avg_search_time': 0.0000015, 'rmi_memory_mb': 0.0003,\n",
    "     'btree_build_time': 0.8, 'btree_avg_search_time': 0.000003, 'btree_memory_mb': 0.025},\n",
    "    {'dataset_size': 1_000_000, 'rmi_build_time': 0.4, 'rmi_avg_search_time': 0.0000018, 'rmi_memory_mb': 0.0004,\n",
    "     'btree_build_time': 1.6, 'btree_avg_search_time': 0.0000035, 'btree_memory_mb': 0.05},\n",
    "    {'dataset_size': 5_000_000, 'rmi_build_time': 2.0, 'rmi_avg_search_time': 0.000002, 'rmi_memory_mb': 0.0008,\n",
    "     'btree_build_time': 8.0, 'btree_avg_search_time': 0.0000045, 'btree_memory_mb': 0.25},\n",
    "    {'dataset_size': 10_000_000, 'rmi_build_time': 4.0, 'rmi_avg_search_time': 0.0000022, 'rmi_memory_mb': 0.0015,\n",
    "     'btree_build_time': 18.0, 'btree_avg_search_time': 0.000005, 'btree_memory_mb': 0.5}\n",
    "]\n",
    "\n",
    "print(\"Resultados del benchmark (simulados o cargados) listos para visualizar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca2afb5",
   "metadata": {},
   "source": [
    "1. Gráfica de Tiempos de Construcción\n",
    "\n",
    "La primera métrica importante es el tiempo que tarda cada índice en construirse (o \"entrenarse\"). Esto es crucial si los datos cambian con frecuencia y el índice necesita ser reconstruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84822521",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Extraer los datos para la gráfica ---\n",
    "sizes = [r['dataset_size'] for r in results]\n",
    "rmi_build_times = [r['rmi_build_time'] for r in results]\n",
    "btree_build_times = [r['btree_build_time'] for r in results]\n",
    "\n",
    "# --- Crear la Gráfica ---\n",
    "plt.figure(figsize=(10, 6)) # Define el tamaño de la figura\n",
    "\n",
    "# Trazar las líneas para cada estructura\n",
    "plt.plot(sizes, rmi_build_times, marker='o', linestyle='-', color='blue', label='RMI - Construcción')\n",
    "plt.plot(sizes, btree_build_times, marker='x', linestyle='--', color='red', label='B-Tree - Construcción')\n",
    "\n",
    "# Añadir títulos y etiquetas\n",
    "plt.title('Tiempo de Construcción del Índice vs. Tamaño del Dataset')\n",
    "plt.xlabel('Tamaño del Dataset')\n",
    "plt.ylabel('Tiempo (segundos)')\n",
    "plt.xscale('log') # Usamos escala logarítmica para el eje X si los tamaños varían mucho\n",
    "plt.yscale('log') # Usamos escala logarítmica para el eje Y si los tiempos varían mucho\n",
    "plt.grid(True, which=\"both\", ls=\"--\", c='0.7') # Añade una cuadrícula para mejor lectura\n",
    "plt.legend() # Muestra la leyenda de las líneas\n",
    "plt.tight_layout() # Ajusta el diseño para que no se corten etiquetas\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretación de la gráfica de construcción:\")\n",
    "print(\"- ¿Qué observas sobre las líneas? ¿Una crece más rápido que la otra?\")\n",
    "print(\"- Un RMI, al entrenar modelos, a menudo tiene un tiempo de construcción más predecible y potencialmente más rápido para grandes datasets que un B-Tree, que inserta elemento a elemento.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fef800",
   "metadata": {},
   "source": [
    "2. Gráfica de Tiempos de Búsqueda (Promedio)\n",
    "\n",
    "Esta es quizás la métrica más importante, ya que un índice se usa principalmente para búsquedas. Queremos ver cuál es más rápido en encontrar un elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b42db6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Extraer los datos para la gráfica ---\n",
    "rmi_search_times = [r['rmi_avg_search_time'] for r in results]\n",
    "btree_search_times = [r['btree_avg_search_time'] for r in results]\n",
    "\n",
    "# --- Crear la Gráfica ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(sizes, rmi_search_times, marker='o', linestyle='-', color='blue', label='RMI - Búsqueda Promedio')\n",
    "plt.plot(sizes, btree_search_times, marker='x', linestyle='--', color='red', label='B-Tree - Búsqueda Promedio')\n",
    "\n",
    "plt.title('Tiempo Promedio de Búsqueda vs. Tamaño del Dataset')\n",
    "plt.xlabel('Tamaño del Dataset')\n",
    "plt.ylabel('Tiempo (segundos)')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log') # Los tiempos de búsqueda suelen ser muy pequeños, log ayuda a ver diferencias.\n",
    "plt.grid(True, which=\"both\", ls=\"--\", c='0.7')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretación de la gráfica de búsqueda:\")\n",
    "print(\"- Los tiempos de búsqueda son muy pequeños, por eso la escala logarítmica es útil.\")\n",
    "print(\"- El RMI busca acercarse a la eficiencia de una simple predicción, mientras que el B-Tree tiene una búsqueda logarítmica garantizada.\")\n",
    "print(\"- Observa cuál línea es más baja y si la diferencia se mantiene o cambia con el tamaño del dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f08f44f",
   "metadata": {},
   "source": [
    "3. Gráfica de Uso de Memoria\n",
    "\n",
    "El espacio ocupado por el índice es crucial, especialmente para sistemas con memoria limitada. ¿Cuál de las dos estructuras es más \"ligera\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37822b2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Extraer los datos para la gráfica ---\n",
    "rmi_memory_usage = [r['rmi_memory_mb'] for r in results]\n",
    "btree_memory_usage = [r['btree_memory_mb'] for r in results]\n",
    "\n",
    "# --- Crear la Gráfica ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(sizes, rmi_memory_usage, marker='o', linestyle='-', color='blue', label='RMI - Memoria (MB)')\n",
    "plt.plot(sizes, btree_memory_usage, marker='x', linestyle='--', color='red', label='B-Tree - Memoria (MB)')\n",
    "\n",
    "plt.title('Uso de Memoria del Índice vs. Tamaño del Dataset')\n",
    "plt.xlabel('Tamaño del Dataset')\n",
    "plt.ylabel('Memoria (Megabytes)')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log') # Uso de escala logarítmica, ya que la memoria también puede variar mucho.\n",
    "plt.grid(True, which=\"both\", ls=\"--\", c='0.7')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretación de la gráfica de memoria:\")\n",
    "print(\"- Este es a menudo el punto fuerte del RMI. Como solo almacena parámetros de modelos, suele ser mucho más compacto.\")\n",
    "print(\"- El B-Tree necesita almacenar todas las claves y punteros en sus nodos, lo que tiende a ocupar más espacio.\")\n",
    "print(\"- Una línea mucho más baja indica un uso de memoria significativamente menor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cb66ab",
   "metadata": {},
   "source": [
    "Conclusiones Clave de las Visualizaciones\n",
    "\n",
    "Al analizar estas tres gráficas juntas, deberíamos poder extraer algunas conclusiones importantes:\n",
    "\n",
    "    RMI (Recursive Model Index): Generalmente se espera que el RMI tenga un menor uso de memoria debido a que almacena modelos en lugar de los datos o punteros directos. En tiempos de búsqueda, puede ser extremadamente rápido, acercándose a la complejidad constante o casi constante en el mejor de los casos, dependiendo de la distribución de los datos y la precisión de sus modelos. Su tiempo de construcción puede ser competitivo, ya que implica entrenar modelos.\n",
    "\n",
    "    B-Tree: Es una estructura muy robusta con garantías de rendimiento logarítmico para búsqueda, inserción y eliminación. Su uso de memoria es típicamente mayor que el RMI, ya que cada nodo debe almacenar varias claves y punteros. El tiempo de construcción puede ser más lento que el RMI para datasets muy grandes, ya que implica una serie de inserciones y posibles divisiones de nodos.\n",
    "\n",
    "En resumen:\n",
    "\n",
    "    Si la memoria es una preocupación crítica y los datos tienen una distribución que los modelos pueden aprender bien, el RMI puede ser una opción superior.\n",
    "    Si necesitas garantías de rendimiento en el peor de los casos, un buen manejo de inserciones y eliminaciones dinámicas, y una estructura probada, el B-Tree sigue siendo una elección excelente y robusta.\n",
    "\n",
    "Estas gráficas nos permiten ver estas ventajas y desventajas de manera visual e intuitiva. Es la culminación de nuestro trabajo, donde la teoría y la implementación se encuentran con la evidencia empírica"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
